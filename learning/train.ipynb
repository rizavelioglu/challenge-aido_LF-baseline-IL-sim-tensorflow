{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "uUc9exkTLthr",
        "QKztd3ehLwzw",
        "QV09naHRL2L3",
        "4OFWD9QSL9dv"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0XbGzPOMQUZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUc9exkTLthr",
        "colab_type": "text"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJl5J0jSLnMx",
        "colab_type": "code",
        "outputId": "1d4b6713-2bfe-4a35-e5a1-e53eadd10273",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.losses import mean_squared_error as MSE\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.layers import GlobalAveragePooling2D, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "\"\"\"Reader Class for reading data\"\"\"\n",
        "import pickle\n",
        "\n",
        "class Reader:\n",
        "\n",
        "    def __init__(self, log_file):\n",
        "        self._log_file = open(log_file, 'rb')\n",
        "\n",
        "    def read(self):\n",
        "        end = False\n",
        "        observations = []\n",
        "        actions = []\n",
        "\n",
        "        while not end:\n",
        "            try:\n",
        "                log = pickle.load(self._log_file)\n",
        "                for entry in log:\n",
        "                    step = entry['step']\n",
        "                    observations.append(step[0])\n",
        "                    actions.append(step[1])\n",
        "            except EOFError:\n",
        "                end = True\n",
        "\n",
        "        return observations, actions\n",
        "\n",
        "    def close(self):\n",
        "        self._log_file.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QKztd3ehLwzw",
        "colab_type": "text"
      },
      "source": [
        "### Plot Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUNv4ydILv24",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function to plot model's validation loss and validation accuracy\n",
        "def plot_model_history(model_history):\n",
        "    fig, axs = plt.subplots(1,2,figsize=(25,8))\n",
        "    # summarize history for accuracy\n",
        "    axs[0].plot(range(1,len(model_history.history['acc'])+1),model_history.history['acc'])\n",
        "    axs[0].plot(range(1,len(model_history.history['val_acc'])+1),model_history.history['val_acc'])\n",
        "    axs[0].set_title('Model Accuracy')\n",
        "    axs[0].set_ylabel('Accuracy')\n",
        "    axs[0].set_xlabel('Epoch')\n",
        "    axs[0].set_xticks(np.arange(1,len(model_history.history['acc'])+1),len(model_history.history['acc'])/10)\n",
        "    axs[0].legend(['train', 'val'], loc='best')\n",
        "    # summarize history for loss\n",
        "    axs[1].plot(range(1,len(model_history.history['loss'])+1),model_history.history['loss'])\n",
        "    axs[1].plot(range(1,len(model_history.history['val_loss'])+1),model_history.history['val_loss'])\n",
        "    axs[1].set_title('Model Loss')\n",
        "    axs[1].set_ylabel('Loss')\n",
        "    axs[1].set_xlabel('Epoch')\n",
        "    axs[1].set_xticks(np.arange(1,len(model_history.history['loss'])+1),len(model_history.history['loss'])/10)\n",
        "    axs[1].legend(['train', 'val'], loc='best')\n",
        "    plt.savefig(STORAGE_LOCATION+'/VGG16#8_model_history.png')\n",
        "    \n",
        "    plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QV09naHRL2L3",
        "colab_type": "text"
      },
      "source": [
        "### Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W85BYi6L2k_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# configuration zone\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "# here we assume the observations have been resized to 60x80\n",
        "OBSERVATIONS_SHAPE = (None, 60, 80, 3)\n",
        "ACTIONS_SHAPE = (None, 2)\n",
        "SEED = 1234\n",
        "# TODO: Give the path where you want to store the trained model\n",
        "STORAGE_LOCATION = \"/content/drive/\"\n",
        "# TODO: Give the path where the training data is stored\n",
        "DATA_LOCATION = \"/content/drive/\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OFWD9QSL9dv",
        "colab_type": "text"
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LotHI8KXL9D3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TODO: Specify name of the data\n",
        "reader = Reader(DATA_LOCATION+'nameOfData.log')\n",
        "\n",
        "observations, actions = reader.read()\n",
        "actions = np.array(actions)\n",
        "observations = np.array(observations)\n",
        "\n",
        "x_train, x_validate, y_train, y_validate = train_test_split(observations, actions, test_size = 0.2, random_state = 2)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center=False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization=False,  # divide each input by its std\n",
        "        zca_whitening=False,  # apply ZCA whitening\n",
        "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0, # Randomly zoom image \n",
        "        width_shift_range=0,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range=0,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip=False,  # randomly flip images\n",
        "        vertical_flip=False)  # randomly flip images\n",
        "\n",
        "train_datagen.fit(x_train)\n",
        "\n",
        "validation_datagen = ImageDataGenerator()\n",
        "validation_datagen.fit(x_validate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vASzw9iyMCKn",
        "colab_type": "text"
      },
      "source": [
        "### Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPyRcvDpMCaH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_model = VGG16(classes=2, input_shape=(60,80,3), weights=None, include_top=False)\n",
        "\n",
        "# add a global spatial average pooling layer\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "predictions = Dense(2)(x)\n",
        "\n",
        "# this is the model we will train\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = SGD(lr=0.01, momentum=0.001, nesterov=False)\n",
        "# optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "# Compile the model\n",
        "model.compile(optimizer = optimizer ,\n",
        "              loss = MSE, \n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss', verbose=1, patience=30)\n",
        "# TODO: Specify name of the model\n",
        "mc = ModelCheckpoint(STORAGE_LOCATION+'nameOfModel.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "history = model.fit_generator(train_datagen.flow(x_train,y_train, batch_size=BATCH_SIZE),\n",
        "                              validation_data = validation_datagen.flow(x_validate,y_validate, batch_size=BATCH_SIZE),\n",
        "                              epochs = EPOCHS,\n",
        "                              verbose=2,  # for hiding print statements\n",
        "                              steps_per_epoch=observations.shape[0] // BATCH_SIZE,\n",
        "                              callbacks=[es, mc],\n",
        "                              shuffle=True)\n",
        "plot_model_history(history)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZxaMNKQ1npUR",
        "colab_type": "text"
      },
      "source": [
        "### Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "xnvVZUOIYQiQ",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(STORAGE_LOCATION+'nameOfModel.h5')\n",
        "# Returns: [loss, accuracy]\n",
        "model.evaluate(x_validate,y_validate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-rj1LIDoQZ_",
        "colab_type": "code",
        "outputId": "dce44fae-c445-49c4-87be-af504b1d3a8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "source": [
        "num = 20\n",
        "preds = model.predict(x_validate[:num])\n",
        "\n",
        "for i in range(num):\n",
        "  print(\"Pred: \", preds[i], \"\\tGT: \", y_validate[i])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pred:  [0.9885629 1.0066956] \tGT:  [1. 1.]\n",
            "Pred:  [0.7629906 0.9382076] \tGT:  [0.89646339 1.        ]\n",
            "Pred:  [0.5505507 0.5559779] \tGT:  [0.58508306 0.57960364]\n",
            "Pred:  [0.6189885  0.08426905] \tGT:  [0.59545575 0.10335627]\n",
            "Pred:  [0.32440728 0.53234667] \tGT:  [0.4859214 0.6787653]\n",
            "Pred:  [0.5814476  0.60452145] \tGT:  [0.55508671 0.60959999]\n",
            "Pred:  [0.87181884 0.6696001 ] \tGT:  [0.72034147 0.44434523]\n",
            "Pred:  [0.6246664  0.62242883] \tGT:  [0.58819145 0.57649525]\n",
            "Pred:  [0.5550587  0.28357962] \tGT:  [0.50332463 0.19548739]\n",
            "Pred:  [0.61963356 0.57528895] \tGT:  [0.59609417 0.56859253]\n",
            "Pred:  [0.530713  0.5984092] \tGT:  [0.60016928 0.56451742]\n",
            "Pred:  [0.12070434 0.58973235] \tGT:  [0.12537573 0.57343629]\n",
            "Pred:  [0.9946303 0.9889532] \tGT:  [1. 1.]\n",
            "Pred:  [0.49480438 0.22583602] \tGT:  [0.46940258 0.22940943]\n",
            "Pred:  [0.37962127 0.695377  ] \tGT:  [0.1925249  0.50628712]\n",
            "Pred:  [0.08598477 0.6732555 ] \tGT:  [0.03688926 0.66192276]\n",
            "Pred:  [0.44178873 0.77202153] \tGT:  [0.41009757 0.75458913]\n",
            "Pred:  [0.5596919  0.49759173] \tGT:  [0.60183485 0.56285185]\n",
            "Pred:  [0.547898  0.2681475] \tGT:  [0.52163718 0.17717484]\n",
            "Pred:  [0.47290438 0.6047241 ] \tGT:  [0.51775981 0.64692689]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}